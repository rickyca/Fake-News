baseline,score,steps,details,predicted_fake__fake,predicted_real__fake,predicted_fake__real,predicted_real__real
0.73210220086,0.948393625095,countvectorizer -> logisticregression,"countvectorizer -> binary=False lowercase=True stop_words=None decode_error=strict vocabulary=None tokenizer=None encoding=utf-8 dtype=<type 'numpy.int64'> analyzer=word ngram_range=(1, 1) max_df=1.0 min_df=1 max_features=None input=content strip_accents=None token_pattern=(?u)\b\w\w+\b preprocessor=None
logisticregression -> warm_start=False C=1 n_jobs=1 verbose=0 intercept_scaling=1 fit_intercept=True max_iter=1000 penalty=l2 multi_class=ovr random_state=None dual=False tol=0.0001 solver=liblinear class_weight=balanced
",2779,115,89,970
0.73969137364,0.919301796104,countvectorizer -> svc,"countvectorizer -> binary=False lowercase=True stop_words=english decode_error=strict vocabulary=None tokenizer=None encoding=utf-8 dtype=<type 'numpy.int64'> analyzer=word ngram_range=(1, 1) max_df=1.0 min_df=1 max_features=None input=content strip_accents=None token_pattern=(?u)\b\w\w+\b preprocessor=None
svc -> kernel=linear C=1 verbose=False probability=False degree=3 shrinking=True max_iter=-1 decision_function_shape=None random_state=None tol=0.001 cache_size=200 coef0=0.0 gamma=auto class_weight=balanced
",2761,163,156,873
0.739185428788,0.957753604857,tfidfvectorizer -> svc,"tfidfvectorizer -> binary=False lowercase=True stop_words=english decode_error=strict vocabulary=None tokenizer=None encoding=utf-8 dtype=<type 'numpy.int64'> smooth_idf=True analyzer=word use_idf=True ngram_range=(1, 1) max_df=1.0 min_df=1 max_features=None input=content sublinear_tf=False strip_accents=None token_pattern=(?u)\b\w\w+\b norm=l2 preprocessor=None
svc -> kernel=linear C=1 verbose=False probability=False degree=3 shrinking=True max_iter=-1 decision_function_shape=None random_state=None tol=0.001 cache_size=200 coef0=0.0 gamma=auto class_weight=balanced
",2860,62,105,926
